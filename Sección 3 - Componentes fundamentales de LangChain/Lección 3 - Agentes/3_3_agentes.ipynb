{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentes\n",
    "\n",
    "**Sumario**\n",
    "\n",
    "1. Introduccion\n",
    "   1. Que es un agente\n",
    "   2. Que es una herramienta\n",
    "   3. Tipos de agentes\n",
    "<br></br>\n",
    "2. Agentes de accion\n",
    "   1. ReAct Zero-shot \n",
    "   2. ReAct Conversacional\n",
    "   3. ReAct Docstore\n",
    "   4. ReAct Self-ask\n",
    "<br></br>\n",
    "3. Agentes de planificacion y ejecucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "# Lee la clave de API desde el archivo de configuración\n",
    "with open('config.txt') as f:\n",
    "    config = dict(line.strip().split('=') for line in f)\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://gpt3tests.openai.azure.com/\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = config.get(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "# Nombre del despliegue en mi Azure OpenAI Studio is \"Davinci003\", el modelo es \"text-davinci-003\"\n",
    "engine = \"Davinci003\"\n",
    "model = \"text-davinci-003\"\n",
    "openai_api_version = \"2023-12-01\" \n",
    "\n",
    "# Nombre del despliegue en mi Azure OpenAI Studio para el modelo de embeddings es \"TextEmbeddingAda002\"\n",
    "embeddings_engine = \"TextEmbeddingAda002\"\n",
    "\n",
    "max_tokens = 1000\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    azure_endpoint=openai.api_base, \n",
    "    azure_deployment=engine, \n",
    "    openai_api_key=config.get(\"OPENAI_API_KEY\", \"\"), \n",
    "    openai_api_version=openai.api_version,\n",
    "    # temperature=0, # Podemos poner la temperatura a 0 si queremos reducir la variabilidad de las respuestas\n",
    ")\n",
    "llm.openai_api_base = openai.api_base \n",
    "llm.max_tokens = max_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - ¿Qué es un agente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El concepto de \"agente\" es una abstracción que permite a nuestro modelo de lenguaje:\n",
    "* Utilizar calculadoras\n",
    "* Uyilizar calendarios\n",
    "* Ejecutar código Python\n",
    "* Buscar en Internet\n",
    "* etc.\n",
    "\n",
    "Este tipo de acciones se realizarán mediante **herramientas**, muchas de las cuales vienen ya dadas por LangChain, y sino siempre podemos diseñar las nuestras propias (como veremos más adelante).\n",
    "\n",
    "Por lo tanto, un agente está compuesto de dos elementos principales:\n",
    "* Un LLM base\n",
    "* Una o multiples herramientas con las que interactuar\n",
    "\n",
    "Dependiendo de la entrada del usuario, el agente puede decidir cuál, si alguna, de estas herramientas llamar. La utilidad de [**LangChain**](https://python.langchain.com/en/latest/index.html#) se hace evidente en este contexto, ya que proporciona un marco de programación versátil para construir tales sistemas.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images_3_3/agent.png\" width=\"800\"/></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - ¿Qué es una herramienta?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Langchain, las herramientas son funciones que pueden ser llamadas por un agente. Se utilizan para realizar tareas específicas, como acceder a datos, generar texto o traducir idiomas.\n",
    "\n",
    "Las herramientas se definen como objetos `Tool` que contienen tres propiedades:\n",
    "\n",
    "* `name`: El nombre de la herramienta.\n",
    "* `description`: Una descripción de la herramienta.\n",
    "* `function`: La función a ejecutar cuando se llama a la herramienta.\n",
    "\n",
    "Las herramientas se utilizan para facilitar la creación de agentes complejos que pueden realizar una amplia gama de tareas. Por ejemplo, un agente que ayuda a los usuarios a resolver problemas técnicos podría usar herramientas para acceder a la documentación, buscar soluciones en línea o generar código.\n",
    "\n",
    "A continuación se presentan algunas herramientas comunes:\n",
    "* Wikipedia\n",
    "* DuckDuckGoSearch\n",
    "* ShellTool\n",
    "\n",
    "Sin embargo hay una gran cantidad de ellas [en la documentación oficial de LangChain](https://python.langchain.com/docs/integrations/tools) (y su número aumenta cada dia). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia\n",
    "\n",
    "Para búsquedas medianamente estructuradas en Wikipedia\n",
    "\n",
    "`pip install wikipedia`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# Para mas informacion acerca de las opciones (e.g), mirar la documentacion:\n",
    "# https://api.python.langchain.com/en/latest/utilities/langchain.utilities.wikipedia.WikipediaAPIWrapper.html#\n",
    "wikipedia_eng = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(\n",
    "    doc_content_chars_max=2000\n",
    "))\n",
    "\n",
    "wikipedia_es = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(\n",
    "    lang=\"es\",\n",
    "    doc_content_chars_max=2000\n",
    "))\n",
    "\n",
    "wikipedia_es.run(\"Open AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DuckDuckGoSearch\n",
    "\n",
    "Para busquedas \"raw\" en internet. \n",
    "\n",
    "**Nota:** En este caso no he encontrado manera de indicarle que haga las búsquedas en español, pero quizas hay una manera. Sino, siempre podemos traducir el resultado como paso intermedio a que nuestro modelo lo procese.\n",
    "\n",
    "`pip install duckduckgo-search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "search.run(\"Open AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shell\n",
    "\n",
    "Permite a los agentes ejecutar comandos de shell. Esto puede ser muy útil para tareas que requieren acceso al sistema operativo, como interactuar con el sistema de archivos o ejecutar aplicaciones.\n",
    "\n",
    "**Nota:** \n",
    "- No funciona en Windows\n",
    "- Es peligroso dejar el control de nuestro sistema de archivos, lo mejor seria encapsularlo en una maquina virtual y prohibirle ciertos comandos (por si acaso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import ShellTool\n",
    "\n",
    "shell_tool = ShellTool()\n",
    "\n",
    "print(shell_tool.run(\n",
    "    {\n",
    "        \"commands\": [\n",
    "            \"echo 'Hello World!'\", \n",
    "            \"ls -lh\"\n",
    "        ]\n",
    "    }\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - Tipos de agentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay dos tipos de agentes principales:\n",
    "* [**Agentes de Acción**](https://python.langchain.com/docs/modules/agents/): estos agentes deciden una acción a tomar y realizan esa acción paso a paso.\n",
    "* [**Agentes de Planificación y Ejecución**](https://api.python.langchain.com/en/latest/plan_and_execute/langchain_experimental.plan_and_execute.agent_executor.PlanAndExecute.html#) (Experimental): estos agentes primero deciden un plan de acciones a tomar y luego ejecutan esas acciones paso a paso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Agentes de Acción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pseudocódigo de alto nivel de los agentes de acción:**\n",
    "\n",
    "1. Se recibe una entrada del usuario.\n",
    "2. El agente decide qué herramienta utilizar, si es que hay alguna, y cuál debe ser la entrada de esa herramienta.\n",
    "3. A continuación, se llama a esa herramienta con esa entrada de herramienta y se registra una observación (esto es simplemente la salida de llamar a esa herramienta con esa entrada de herramienta).\n",
    "4. Ese historial, la entrada de herramienta y observación final se devuelve al agente, y éste decide qué paso dar a continuación.\n",
    "5. Esto se repite hasta que el agente decide que ya no necesita utilizar ninguna herramienta, y entonces responde directamente al usuario.\n",
    "\n",
    "**4 tipos de agentes de acción (inspirados del paper [\"ReAct: Synergizing Reasoning and Acting in Language Models\"](https://arxiv.org/abs/2210.03629)):**\n",
    "* ReAct Zero-shot \n",
    "* ReAct Conversacional\n",
    "* ReAct Docstore\n",
    "* ReAct Self-ask\n",
    "\n",
    "[AgentTypes en la documentacion de LangChain](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent_types.AgentType.html#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - ReAct Zero-shot\n",
    "\n",
    "`pip install numexpr`\n",
    "\n",
    "----\n",
    "\n",
    "**Nota importante:** Al interactuar con agentes, es muy importante establecer el parámetro `max_iterations` porque los agentes pueden quedarse atrapados en bucles infinitos que consumen muchos tokens. El valor predeterminado es 15 para permitir el uso de muchas herramientas y razonamientos complejos, pero para la mayoría de las aplicaciones, es mejor mantenerlo mucho más bajo.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, Tool, load_tools, initialize_agent\n",
    "\n",
    "tools = load_tools(\n",
    "    [\"llm-math\"], \n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "zero_shot_agent_executor = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent_executor(\"Cuanto es 100 + 25?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nos fijamos, el agente utiliza el inglés como idioma \"base\". Como hemos visto en otras clases, podemos modificar este comportamiento modificando las prompts de la cadena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zero_shot_agent_executor.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, vamos a tomar un enfoque diferente y vamos a traducir el texto de español a inglés antes de pasarselo al agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "def call_agent_with_translate(agent, es_eng_chain, eng_es_chain, query):\n",
    "\n",
    "    print(f\"Input: {query}\")\n",
    "\n",
    "    with get_openai_callback() as cb:\n",
    "        query_translated = es_eng_chain(query)[\"text\"]\n",
    "        query_translated = query_translated.replace('\\n', '') # Simplemente para mostrarlo mejor en este ejemplo\n",
    "        es_eng_token_count = cb.total_tokens\n",
    "    print(f\"Input (traducido al inglés): {query_translated}\")\n",
    "\n",
    "    with get_openai_callback() as cb:\n",
    "        result = agent(query_translated)\n",
    "        agent_token_count = cb.total_tokens\n",
    "    print(f\"Output: {result['output']}\")\n",
    "\n",
    "    with get_openai_callback() as cb:\n",
    "        output_translated = eng_es_chain(result[\"output\"])[\"text\"]\n",
    "        output_translated = output_translated.replace('\\n', '') # Simplemente para mostrarlo mejor en este ejemplo\n",
    "        eng_es_token_count = cb.total_tokens\n",
    "    print(f\"Output (traducido al español): {output_translated}\")\n",
    "\n",
    "    total_tokens = es_eng_token_count + agent_token_count + eng_es_token_count\n",
    "    print(f'He usado un total de {total_tokens} tokens')\n",
    "\n",
    "    return result\n",
    "\n",
    "# Chain para traducir el texto de entrada de español a inglés\n",
    "translate_eng_es_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following spanish text to english (write only the translated text): {input}\"\n",
    ")\n",
    "translate_eng_es_chain = LLMChain(llm=llm, prompt=translate_eng_es_prompt)\n",
    "# Chain para traducir el texto de salida del modelo de inglés a español\n",
    "translate_es_eng_prompt = ChatPromptTemplate.from_template(\n",
    "    # \"Traduce el siguiente texto a español, deja las operaciones matematicas sin modificar: {input}\"\n",
    "    \"Si el siguiente texto esta en inglés, traducelo al español, en caso contrario, simplemente devuelve el mismo texto: {input}\"\n",
    ")\n",
    "translate_es_eng_chain = LLMChain(llm=llm, prompt=translate_es_eng_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = call_agent_with_translate(\n",
    "    zero_shot_agent_executor, \n",
    "    translate_eng_es_chain,\n",
    "    translate_es_eng_chain,\n",
    "    \"Podrias decirme cual el resultado de 100 + 25?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - ReAct Conversacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El agente zero-shot es interesante, pero **no tiene memoria**. ¿Qué pasa si queremos un asistente que recuerde las cosas de las que hemos hablado y que también pueda razonar sobre ellas y utilizar herramientas? Para eso tenemos el agente ReAct Conversacional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "tools = load_tools(\n",
    "    [\"llm-math\"], \n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "conversational_agent_executor = initialize_agent(\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION ,\n",
    "    tools=tools, \n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "result = call_agent_with_translate(\n",
    "    conversational_agent_executor, \n",
    "    translate_eng_es_chain,\n",
    "    translate_es_eng_chain,\n",
    "    \"Podrias decirme cual el resultado de 100 + 25?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = call_agent_with_translate(\n",
    "    conversational_agent_executor, \n",
    "    translate_eng_es_chain,\n",
    "    translate_es_eng_chain,\n",
    "    \"Que es lo último que te he preguntado en nuestra conversación?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - ReAct Docstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este tipo de agente es similar a los que hemos visto hasta ahora, pero incluye la interacción con un almacén de documentos. Solo tendrá dos herramientas a su disposición:\n",
    "\n",
    "* **Search** (Búsqueda). El agente usa esta herramienta para encontrar un artículo relevante.\n",
    "* **Lookup** (Consulta). El agente intenta encontrar la información correcta en el artículo.\n",
    "\n",
    "Es el agente por defecto en el caso que queramos hacer **búsquedas simples** en wikipedia o almacenenes de documentos similares.\n",
    "\n",
    "----\n",
    "\n",
    "**Nota:** ReAct Docstore no está pensado para trabajar con memoria por defecto. En tal caso tendriamos que preparar nuestro propio Agente customizado\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "from langchain import Wikipedia\n",
    "from langchain.agents.react.base import DocstoreExplorer\n",
    "\n",
    "# Podemos cambiar el idiomas de las paginas que recupere el agente \n",
    "# (lo cual podria afectar a la calidad y cantidad de información disponible)\n",
    "#\n",
    "# Para mas informacion: https://wikipedia.readthedocs.io/en/latest/quickstart.html\n",
    "wikipedia.set_lang(\"en\")\n",
    "\n",
    "docstore=DocstoreExplorer(Wikipedia())\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=docstore.search,\n",
    "        description='search wikipedia'\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Lookup\",\n",
    "        func=docstore.lookup,\n",
    "        description='lookup a term in wikipedia'\n",
    "    )\n",
    "]\n",
    "\n",
    "docstore_agent_executor = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.REACT_DOCSTORE, \n",
    "    verbose=True,\n",
    "    max_iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El prompt asociado al modelo difiere de los anteriores en cuanto que contiene varios ejemplos del bucle Pregunta > Pensamiento > Acción > Observación, que incluyen las herramientas de búsqueda y consulta.\n",
    "\n",
    "**Nota:** Este bucle se explica con más detalle (al igual que con mas ejemplos) en el paper original [\"ReAct: Synergizing Reasoning and Acting in Language Models\"](https://arxiv.org/abs/2210.03629) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docstore_agent_executor.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = call_agent_with_translate(\n",
    "    docstore_agent_executor, \n",
    "    translate_eng_es_chain,\n",
    "    translate_es_eng_chain,\n",
    "    \"Cuales han sido las principales investigaciones del filosofo griego Aristoteles?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 - ReAct Self-ask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es nuestra primera elección de agente para cuando queremos utilizar un LLM con el objetivo de extraer información con un motor de búsqueda. El agente hará preguntas de seguimiento y utilizará la funcionalidad de búsqueda para obtener respuestas intermedias que lo ayuden a llegar a una respuesta final.\n",
    "\n",
    "Utilizaremos el motor de búsqueda DuckDuckGo porque es gratuito y no requiere una clave API.\n",
    "\n",
    "----\n",
    "\n",
    "**Nota:** Al igual que ReAct Docstore, ReAct Self-ask no está pensado para trabajar con memoria por defecto. En tal caso tendriamos que preparar nuestro propio Agente customizado\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description='duckduckgo search'\n",
    "    )\n",
    "]\n",
    "\n",
    "self_ask_with_search_agent_executor = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.SELF_ASK_WITH_SEARCH,\n",
    "    verbose=True, \n",
    "    max_iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver a continuación, el prompt del agente es básicamente una serie de ejemplos para mostrarle al LLM cómo hacer preguntas de seguimiento a una herramienta de búsqueda hasta que pueda llegar a la respuesta final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(self_ask_with_search_agent_executor.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregunta = \"Cual es el nombre de la esposa del actual presidente de los Estados Unidos de America?\"\n",
    "\n",
    "result = call_agent_with_translate(\n",
    "    self_ask_with_search_agent_executor, \n",
    "    translate_eng_es_chain,\n",
    "    translate_es_eng_chain,\n",
    "    pregunta\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Agentes de Planificación y Ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los agentes \"Plan-and-Execute\" (PaE) logran un objetivo planificando primero qué hacer y luego ejecutando las subtareas. Esta idea se inspira en gran medida en [BabyAGI](https://github.com/yoheinakajima/babyagi) y luego en el documento [\"Plan-and-Solve\" (Wang et al., 2023)](https://arxiv.org/pdf/2305.04091.pdf).\n",
    "* La planificación casi siempre la realiza un LLM.\n",
    "* La ejecución generalmente la realiza un agente de acción (equipado con herramientas).\n",
    "\n",
    "**Pseudocódigo de alto nivel de los agentes PaE:**\n",
    "* Se recibe alguna entrada del usuario\n",
    "* El **planificador** enumera los pasos a seguir\n",
    "* El **ejecutor** recorre la lista de pasos, ejecutándolos\n",
    "\n",
    "**Forma típica de construir un agente PaE:**\n",
    "* **Planificador:** actua a modo de \"cerebro\" y define que pasos se deben seguir. Se puede invocar mediante la función `load_chat_planner(llm)`.\n",
    "  * LLM\n",
    "* **Ejecutor:** decide qué herramientas llamar en cada paso y en qué orden. Se puede invocar con la función `load_agent_executor(llm, tools)`.\n",
    "  * LLM\n",
    "  * Kit de herramientas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMMathChain\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    ),\n",
    "    # Esta es la manera \"formal\" de llamar a 'llm-math'\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about math\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "\n",
    "planner = load_chat_planner(llm)\n",
    "executor = load_agent_executor(llm, tools, verbose=True)\n",
    "pae_agent_executor = PlanAndExecute(planner=planner, executor=executor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregunta = \"Quién es el actual primer ministro de Gran Bretaña? Cual es su edad elevado a 0.43?\"\n",
    "\n",
    "result = call_agent_with_translate(\n",
    "    pae_agent_executor, \n",
    "    translate_eng_es_chain,\n",
    "    translate_es_eng_chain,\n",
    "    pregunta\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siguiente\n",
    "\n",
    "En la siguiente lección, veremos cómo podemos definir nuestras propias herramientas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
